{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the complete File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanicCompleteData= pd.read_csv(\"C:/MyFolder/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the file we have total 148 records. From these records we have decided to keep 120 for training purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = titanicCompleteData.head(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train: (120, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of train: {}\".format(trainData.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The reamining 28 records will be used for testing purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "untouchedTestData = titanicCompleteData.tail(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the test records, we are deleting the 'class' columns.\n",
    "#ONE THING IMPORTANT IS THAT WE ARE NOT DELETING FROM THE ACTUAL FILE BUT FROM THE DATAFRAME.\n",
    "#ANOTHER IMPORTANT THING IS THAT- HERE WE HAVE ONE FILE WHICH WE HAVE DIVIDED INTO TWO DATAFRAMES.\n",
    "#IF WE WERE GIVEN TWO FILES (TEST & TRAIN) WE COULD HAVE SIMPLY LOADED BOTH OF THEM INTO TWO DIFFERENT DATAFRAMES.\n",
    "#ONE FILE | TWO FILE APPROACH MAKES NO DIFFERENCE ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "del untouchedTestData['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of test: (28, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of test: {}\".format(untouchedTestData.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right now our Training Dataframe is of (120, 5) dimention.\n",
    "# and our Testing Dataframe is of (28, 4) dimention.\n",
    "\n",
    "#Now, we are going introduce 3 new columns (in both Training and Testing Dataframes)\n",
    "#3 new columns will be for class.Default values = 0  [SPARSE MATRIX WAY !!!]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rvaish\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\rvaish\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "new_age_columns = [\"Iris-setosa\",\"Iris-versicolor\",\"Iris-virginica\"]\n",
    "\n",
    "for newCol in new_age_columns:\n",
    "    trainData[newCol] =0\n",
    "    \n",
    "for newCol in new_age_columns:\n",
    "    untouchedTestData[newCol] =0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train: (120, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of train: {}\".format(trainData.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train: (28, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of train: {}\".format(untouchedTestData.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now as for 3 newly created columns we have assigned 0 as default values ; but that's not going to take things forward. We need to assign respective values into the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rvaish\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\rvaish\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\rvaish\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "trainData['Iris-setosa'] = np.where(trainData['class']==1, '1', '0')\n",
    "trainData['Iris-versicolor'] = np.where(trainData['class']==2, '1', '0')\n",
    "trainData['Iris-virginica'] = np.where(trainData['class']==3, '1', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now choose the important variables (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectdColumns = [\"sepallength\",\"sepalwidth\",\"petallength\",\"petalwidth\",\"Iris-setosa\",\"Iris-versicolor\",\"Iris-virginica\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have Sparse Matrix is prepared, time to apply ML modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(trainData[selectdColumns], trainData[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANT: NOW WE ARE SPLITTING OUR TRAIN DATAFRAME IN 80% 20% RATIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 1 2 1 1 1 1 2 1 2 1 2 3 2 1 1 3 2 2 2 1 1]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "all_X = trainData[selectdColumns]\n",
    "all_y = trainData['class']\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    all_X, all_y, test_size=0.20,random_state=0)\n",
    "\n",
    "rf.fit(train_X, train_y)\n",
    "predictions = rf.predict(test_X)\n",
    "print(predictions)\n",
    "accuracy = accuracy_score(test_y, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 FOLD CROSS VALIDATION- Therefore, 10 results in the List.\n",
    "#Post that, taking mean of the calculated scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier (n_estimators=100)\n",
    "scores = cross_val_score(rf, all_X, all_y, cv=10)\n",
    "scores.sort()\n",
    "accuracy = scores.mean()\n",
    "\n",
    "print(scores)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "############  NOW TIME TO USE UNSEEN DATA #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = untouchedTestData "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallength</th>\n",
       "      <th>sepalwidth</th>\n",
       "      <th>petallength</th>\n",
       "      <th>petalwidth</th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepallength  sepalwidth  petallength  petalwidth  Iris-setosa  \\\n",
       "120          7.7         2.8          6.7         2.0            0   \n",
       "121          6.3         2.7          4.9         1.8            0   \n",
       "122          6.7         3.3          5.7         2.1            0   \n",
       "123          7.2         3.2          6.0         1.8            0   \n",
       "124          6.2         2.8          4.8         1.8            0   \n",
       "125          6.1         3.0          4.9         1.8            0   \n",
       "126          6.4         2.8          5.6         2.1            0   \n",
       "127          7.2         3.0          5.8         1.6            0   \n",
       "128          7.4         2.8          6.1         1.9            0   \n",
       "129          7.9         3.8          6.4         2.0            0   \n",
       "130          6.4         2.8          5.6         2.2            0   \n",
       "131          6.3         2.8          5.1         1.5            0   \n",
       "132          6.1         2.6          5.6         1.4            0   \n",
       "133          7.7         3.0          6.1         2.3            0   \n",
       "134          6.3         3.4          5.6         2.4            0   \n",
       "135          6.4         3.1          5.5         1.8            0   \n",
       "136          6.0         3.0          4.8         1.8            0   \n",
       "137          6.9         3.1          5.4         2.1            0   \n",
       "138          6.7         3.1          5.6         2.4            0   \n",
       "139          6.9         3.1          5.1         2.3            0   \n",
       "140          5.8         2.7          5.1         1.9            0   \n",
       "141          6.8         3.2          5.9         2.3            0   \n",
       "142          6.7         3.3          5.7         2.5            0   \n",
       "143          6.7         3.0          5.2         2.3            0   \n",
       "144          6.3         2.5          5.0         1.9            0   \n",
       "145          6.5         3.0          5.2         2.0            0   \n",
       "146          6.2         3.4          5.4         2.3            0   \n",
       "147          5.9         3.0          5.1         1.8            0   \n",
       "\n",
       "     Iris-versicolor  Iris-virginica  \n",
       "120                0               0  \n",
       "121                0               0  \n",
       "122                0               0  \n",
       "123                0               0  \n",
       "124                0               0  \n",
       "125                0               0  \n",
       "126                0               0  \n",
       "127                0               0  \n",
       "128                0               0  \n",
       "129                0               0  \n",
       "130                0               0  \n",
       "131                0               0  \n",
       "132                0               0  \n",
       "133                0               0  \n",
       "134                0               0  \n",
       "135                0               0  \n",
       "136                0               0  \n",
       "137                0               0  \n",
       "138                0               0  \n",
       "139                0               0  \n",
       "140                0               0  \n",
       "141                0               0  \n",
       "142                0               0  \n",
       "143                0               0  \n",
       "144                0               0  \n",
       "145                0               0  \n",
       "146                0               0  \n",
       "147                0               0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout[selectdColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-29cc3c129311>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mall_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'columns' is not defined"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier (n_estimators=100)\n",
    "rf.fit(all_X,all_y)\n",
    "predictions = rf.predict(holdout[selectdColumns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have predictions. And from the CSV File we have the actual outputs.\n",
    "#Let's assign the actual outputs from the CSV into cheatvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheatvalues = [0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "1,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "1,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0,\n",
    "0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cheatvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(cheatvalues, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7296650717703349\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THE END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
